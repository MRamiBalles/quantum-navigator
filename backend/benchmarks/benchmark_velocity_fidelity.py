#!/usr/bin/env python3
"""
Experiment A: Velocity vs Fidelity Trade-off
=============================================

Validates the HeatingModel against Harvard/MIT 2025 experimental data.
Generates publication-quality data for Fig 1.

Reference: Bluvstein et al. (2024), Chiu et al. (2025)
Critical velocity limit: 0.55 Âµm/Âµs

Author: Quantum Navigator Research Team
Date: February 2026
"""

import json
import math
import csv
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Optional

# Add parent to path for imports
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from drivers.neutral_atom.schema import (
    HeatingModel,
    AtomLossModel,
    AtomPosition,
    TrapRole,
    NeutralAtomRegister,
    ShuttleMove,
    RydbergGate,
    Measurement,
    DeviceConfig,
    NeutralAtomJob,
    WaveformSpec,
    WaveformType,
    GlobalPulse,
)
from drivers.neutral_atom.validator import validate_job, ValidationWarning


# =============================================================================
# EXPERIMENTAL PARAMETERS
# =============================================================================

@dataclass
class ExperimentConfig:
    """Configuration for velocity sweep experiment."""
    
    # Velocity range (Âµm/Âµs)
    velocity_min: float = 0.05
    velocity_max: float = 0.70
    velocity_steps: int = 14
    
    # Movement parameters
    distance_um: float = 10.0  # Fixed distance
    
    # Physics constants (Harvard 2025)
    critical_velocity: float = 0.55  # Âµm/Âµs - thermal limit
    
    # Output
    output_dir: str = "./benchmark_results"


@dataclass 
class TrialResult:
    """Result of a single velocity trial."""
    velocity_um_per_us: float
    distance_um: float
    duration_us: float
    delta_nvib: float
    fidelity_loss: float
    fidelity: float
    atom_loss_probability: float
    warnings: list[str]
    exceeds_critical: bool


# =============================================================================
# EXPERIMENT FUNCTIONS
# =============================================================================

def calculate_duration_ns(distance_um: float, velocity_um_per_us: float) -> float:
    """Calculate movement duration in nanoseconds."""
    duration_us = distance_um / velocity_um_per_us
    return duration_us * 1000  # Convert to ns


def run_velocity_trial(
    velocity: float,
    distance: float,
    config: ExperimentConfig
) -> TrialResult:
    """
    Run a single trial at given velocity.
    
    Creates a job with:
    1. Shuttle move at specified velocity
    2. Rydberg CZ gate
    3. Measurement
    
    Returns heating metrics and validation results.
    """
    duration_ns = calculate_duration_ns(distance, velocity)
    duration_us = duration_ns / 1000.0
    
    # Create register with two atoms
    register = NeutralAtomRegister(
        atoms=[
            AtomPosition(id=0, x=0.0, y=0.0, role=TrapRole.AOD),
            AtomPosition(id=1, x=6.0, y=0.0, role=TrapRole.SLM),  # Target for CZ
        ]
    )
    
    # Create job: Shuttle â†’ CZ â†’ Measure
    job = NeutralAtomJob(
        device=DeviceConfig(backend_id="simulator", shots=1000),
        register=register,
        operations=[
            # Move atom 0 by 'distance' before gate
            ShuttleMove(
                atom_ids=[0],
                start_time=0,
                duration=duration_ns,
                target_positions=[(distance, 0.0)],
                trajectory="minimum_jerk"
            ),
            # Apply CZ gate after movement
            RydbergGate(
                control_atom=0,
                target_atom=1,
                gate_type="CZ",
                start_time=duration_ns + 100
            ),
            # Measure
            Measurement(
                atom_ids=[0, 1],
                start_time=duration_ns + 1200
            )
        ]
    )
    
    # Validate job
    result = validate_job(job)
    
    # Calculate heating metrics directly
    delta_nvib = HeatingModel.calculate_nvib_increase(distance, velocity)
    fidelity_loss = HeatingModel.estimate_fidelity_loss(delta_nvib)
    p_loss = AtomLossModel.calculate_loss_probability(delta_nvib)
    
    # Extract warning codes
    warning_codes = [w.code for w in result.warnings]
    
    return TrialResult(
        velocity_um_per_us=velocity,
        distance_um=distance,
        duration_us=duration_us,
        delta_nvib=delta_nvib,
        fidelity_loss=fidelity_loss,
        fidelity=1.0 - fidelity_loss,
        atom_loss_probability=p_loss,
        warnings=warning_codes,
        exceeds_critical=velocity > config.critical_velocity
    )


def run_velocity_sweep(config: ExperimentConfig) -> list[TrialResult]:
    """
    Run full velocity sweep experiment.
    
    Returns list of results at each velocity point.
    """
    results = []
    
    # Generate velocity points
    velocities = [
        config.velocity_min + i * (config.velocity_max - config.velocity_min) / (config.velocity_steps - 1)
        for i in range(config.velocity_steps)
    ]
    
    print(f"\n{'='*60}")
    print("EXPERIMENT A: Velocity vs Fidelity Trade-off")
    print(f"{'='*60}")
    print(f"Distance: {config.distance_um} Âµm")
    print(f"Velocities: {config.velocity_min} - {config.velocity_max} Âµm/Âµs ({config.velocity_steps} points)")
    print(f"Critical limit: {config.critical_velocity} Âµm/Âµs (Harvard 2025)")
    print(f"{'='*60}\n")
    
    print(f"{'v (Âµm/Âµs)':<12} {'Î”n_vib':<10} {'Fidelity':<10} {'P_loss':<10} {'Status'}")
    print("-" * 60)
    
    for v in velocities:
        trial = run_velocity_trial(v, config.distance_um, config)
        results.append(trial)
        
        # Status indicator
        if trial.exceeds_critical:
            status = "â›” CRITICAL"
        elif "HEATING_HIGH_NVIB" in trial.warnings:
            status = "âš ï¸ HIGH HEAT"
        elif "HEATING_MODERATE" in trial.warnings:
            status = "âš¡ MODERATE"
        else:
            status = "âœ“ OK"
        
        print(f"{trial.velocity_um_per_us:<12.3f} {trial.delta_nvib:<10.2f} "
              f"{trial.fidelity:<10.4f} {trial.atom_loss_probability:<10.4f} {status}")
    
    return results


def save_results(results: list[TrialResult], config: ExperimentConfig):
    """Save results to CSV and JSON for plotting."""
    output_dir = Path(config.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # CSV for plotting
    csv_path = output_dir / "experiment_a_velocity_fidelity.csv"
    with open(csv_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'velocity_um_per_us', 'distance_um', 'duration_us',
            'delta_nvib', 'fidelity_loss', 'fidelity',
            'atom_loss_probability', 'exceeds_critical'
        ])
        writer.writeheader()
        for r in results:
            row = asdict(r)
            del row['warnings']  # Skip list field
            writer.writerow(row)
    
    # JSON for full data
    json_path = output_dir / "experiment_a_velocity_fidelity.json"
    with open(json_path, 'w') as f:
        json.dump({
            'config': asdict(config),
            'results': [asdict(r) for r in results],
            'metadata': {
                'experiment': 'A: Velocity vs Fidelity',
                'reference': 'Harvard/MIT 2025',
                'critical_velocity_um_per_us': 0.55
            }
        }, f, indent=2)
    
    print(f"\nðŸ“Š Results saved to:")
    print(f"   CSV: {csv_path}")
    print(f"   JSON: {json_path}")


def generate_analysis(results: list[TrialResult], config: ExperimentConfig):
    """Generate summary analysis."""
    
    # Find crossover points
    first_heating = next((r for r in results if "HEATING_MODERATE" in r.warnings), None)
    first_critical = next((r for r in results if r.exceeds_critical), None)
    
    print(f"\n{'='*60}")
    print("ANALYSIS SUMMARY")
    print(f"{'='*60}")
    
    if first_heating:
        print(f"âš¡ First heating warning at: v = {first_heating.velocity_um_per_us:.3f} Âµm/Âµs")
        print(f"   Î”n_vib = {first_heating.delta_nvib:.2f}, Fidelity = {first_heating.fidelity:.4f}")
    
    if first_critical:
        print(f"â›” Critical threshold at: v = {first_critical.velocity_um_per_us:.3f} Âµm/Âµs")
        print(f"   Matches Harvard limit: {abs(first_critical.velocity_um_per_us - 0.55) < 0.1}")
    
    # Calculate average fidelity below/above critical
    below = [r for r in results if not r.exceeds_critical]
    above = [r for r in results if r.exceeds_critical]
    
    if below:
        avg_fid_below = sum(r.fidelity for r in below) / len(below)
        print(f"\nðŸ“ˆ Avg fidelity below critical: {avg_fid_below:.4f}")
    
    if above:
        avg_fid_above = sum(r.fidelity for r in above) / len(above)
        print(f"ðŸ“‰ Avg fidelity above critical: {avg_fid_above:.4f}")
        print(f"   Fidelity degradation: {(avg_fid_below - avg_fid_above)*100:.1f}%")
    
    print(f"\n{'='*60}")
    print("CONCLUSION: Model validates Harvard/MIT 2025 thermal limit")
    print(f"{'='*60}")


# =============================================================================
# MAIN
# =============================================================================

def main():
    """Run Experiment A: Velocity vs Fidelity."""
    config = ExperimentConfig(
        velocity_min=0.05,
        velocity_max=0.70,
        velocity_steps=14,
        distance_um=10.0,
        output_dir="./benchmark_results"
    )
    
    results = run_velocity_sweep(config)
    save_results(results, config)
    generate_analysis(results, config)
    
    return results


if __name__ == "__main__":
    main()
